{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94afef6b",
   "metadata": {},
   "source": [
    "# Naive Bayesian Classifier\n",
    "\n",
    "\n",
    "The Naive Bayes classifier makes a naive assumption that the input features are conditionally independent given the class, which allows us to simplify the likelihood term as:\n",
    "\n",
    "$$P(x|c) = P(x1|c) * P(x2|c) * ... * P(xn|c)$$\n",
    "\n",
    "\n",
    "where:\n",
    "\n",
    "-   xi is the ith input feature.\n",
    "\n",
    "Therefore, the Naive Bayes classifier can be written as:\n",
    "\n",
    "$$P(c|x) = P(c) * P(x1|c) * P(x2|c) * ... * P(xn|c) / P(x)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128cb13d",
   "metadata": {},
   "source": [
    "## Training Phase\n",
    "    \n",
    "    -   Collect and preprocess the training data: Gather a labeled dataset where each instance is associated with a known class label.\n",
    "    \n",
    "    -   Estimate class probabilities: Calculate the prior probability of each class based on the frequency or proportion of instances in the training data. The prior probability of class C is denoted as P(C).\n",
    "    \n",
    "    -   Estimate feature probabilities: For each feature in the dataset, calculate the likelihood of observing a particular value given each class. This is done by counting the occurrences of each feature value within each class. The likelihood of feature X taking on value V given class C is denoted as P(X=V|C).\n",
    "\n",
    "Prior Probability: P(C) = Number of instances in class C / Total number of instances\n",
    "\n",
    "Likelihood: P(X=V|C) = Number of instances in class C with feature X = V / Number of instances in class C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959c5ed6",
   "metadata": {},
   "source": [
    "## Prediction phase\n",
    "    \n",
    "    -   Collect and preprocess the new data: Obtain the new, unlabeled data for which you want to make predictions. Preprocess the data to match the format of the training data.\n",
    "        \n",
    "    -   Calculate the conditional probabilities: For each class, calculate the conditional probability of observing the given features. This is done by multiplying the likelihoods of the observed feature values for that class. The conditional probability of class C given features X is denoted as P(C|X).\n",
    "        \n",
    "    -   Apply Bayes' theorem: Use Bayes' theorem to calculate the posterior probability of each class given the observed features. Bayes' theorem states that the posterior probability is proportional to the product of the prior probability and the conditional probability:\n",
    "        \n",
    "        P(C|X) = (P(X|C) * P(C)) / P(X)\n",
    "        \n",
    "    -   Select the predicted class: Choose the class with the highest posterior probability as the predicted class for the new instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64609174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior Probabilities:\n",
      "Not Spam: 0.49999999999999994\n",
      "Spam: 0.5000000000000002\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Create the feature matrix\n",
    "X = np.array([[2, 3], [3, 4], [4, 5], [2, 1], [3, 2], [4, 3]])\n",
    "# Create the target labels\n",
    "y = np.array(['Spam', 'Spam', 'Not Spam', 'Spam', 'Not Spam', 'Not Spam'])\n",
    "\n",
    "# Create a Naive Bayes Classifier\n",
    "clf = GaussianNB()\n",
    "\n",
    "# Fit the model with the training data\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Create a new observation to predict its class\n",
    "new_observation = np.array([[3, 3]])\n",
    "\n",
    "# Calculate the posterior probabilities for the new observation\n",
    "posterior_probs = clf.predict_proba(new_observation)\n",
    "\n",
    "# Display the posterior probabilities\n",
    "print(\"Posterior Probabilities:\")\n",
    "for i, class_label in enumerate(clf.classes_):\n",
    "    print(f\"{class_label}: {posterior_probs[0][i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd58264",
   "metadata": {},
   "source": [
    "The calculated posterior probabilities for the new observation are approximately 0.5 for both the \"Not Spam\" and \"Spam\" classes. Since the probabilities are close to each other, it suggests that the new observation is equally likely to belong to either class based on the given features.\n",
    "\n",
    "Therefore, we can conclude that the Naive Bayes classifier is uncertain about the class assignment for the new observation, and further investigation or additional features may be needed to make a more confident prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
