{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d7093eb-2052-4cdf-ac6c-a59499a3e257",
   "metadata": {},
   "source": [
    "# Inverted Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0f47bd-950b-4d86-a6dc-94d1e3896f77",
   "metadata": {},
   "source": [
    "This notebook demonstrates a simple indexer that constructs inverted index from raw text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c27f9e3d-da74-43e6-8958-687996728a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d6b9a7-eebb-4faa-b785-9d6979b431a2",
   "metadata": {},
   "source": [
    "Download the *popular* subset of NLTK data for tokeniser etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af810433-1d5d-4cd8-aa92-a1d5ac26a8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\jaspe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130597a7-3264-42f3-b3f8-74f68dc8bbff",
   "metadata": {},
   "source": [
    "A set of 3 documents about the Australian National University is provided for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc9d419-da2e-48bd-8ade-b1ee31925859",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"Spring is his favourite season, When the breeze casually messes up his hair. He is not worried about the world’s noisiness, Just thinking about the changes in his life. There’s just fifteen minutes until lunch break, From morning to night it didn’t go as easily as he thought.\\n\",\n",
    "    \"A secure life will not necessarily bring happiness, Unable to forget the dream in his heart. This year according to the lunar calendar March the 6th he turns 22, Just putting aside textbooks and leaving home to see the world. Yet he realized that there were many worries to face. He often wishes to go back to that year when he was 12, Just needing to go to school and living innocently and without worries\\n\"   \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af09bc8-0b72-44a8-a159-ebae90ac72ef",
   "metadata": {},
   "source": [
    "## Indexer Step 1\n",
    "Scan the documents (lyrics from david tao - twenty two) in `doc` for indexable terms and produce a list of `(token, docID)` tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fe10b71-1000-4fff-a5fc-67e7feb0c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "# produce a list of (token, docID) tuples\n",
    "\n",
    "token_tuples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30e5ce8f-95a2-409a-9e67-9e950924ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (docid, doc) in enumerate(docs):\n",
    "    token_tuples.extend([(token, docid) for token in word_tokenize(doc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8497f9ce-03fe-4512-a7b0-ddc1ef52c5d7",
   "metadata": {},
   "source": [
    "Print the total number of `(token, docID)` tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0e09172-59d6-4031-884d-063abe7b9a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of (token, docID) tuples: 141\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of (token, docID) tuples: {len(token_tuples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78ed99f7-1211-45df-ba99-f9fa639c9728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Spring', 0),\n",
       " ('is', 0),\n",
       " ('his', 0),\n",
       " ('favourite', 0),\n",
       " ('season', 0),\n",
       " (',', 0),\n",
       " ('When', 0),\n",
       " ('the', 0),\n",
       " ('breeze', 0),\n",
       " ('casually', 0),\n",
       " ('messes', 0),\n",
       " ('up', 0),\n",
       " ('his', 0),\n",
       " ('hair', 0),\n",
       " ('.', 0),\n",
       " ('He', 0),\n",
       " ('is', 0),\n",
       " ('not', 0),\n",
       " ('worried', 0),\n",
       " ('about', 0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "token_tuples[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6509ba-33c7-4f11-82d1-19c89e0c9df8",
   "metadata": {},
   "source": [
    "## Indexer Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d0483-c893-4370-b070-ceff3aacc86b",
   "metadata": {},
   "source": [
    "Sort token tuples `(token, docID)` (first by `token` then by `docID`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a327a9cd-c8c5-43de-a277-11602748687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort token tuples\n",
    "\n",
    "sorted_token_tuples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba2775de-7093-4d9f-a905-06ce5d91e0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_token_tuples = sorted(token_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3d5a1ea-3ca4-4952-ac8d-3e9340737b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Spring', 0),\n",
       " ('is', 0),\n",
       " ('his', 0),\n",
       " ('favourite', 0),\n",
       " ('season', 0),\n",
       " (',', 0),\n",
       " ('When', 0),\n",
       " ('the', 0),\n",
       " ('breeze', 0),\n",
       " ('casually', 0),\n",
       " ('messes', 0),\n",
       " ('up', 0),\n",
       " ('his', 0),\n",
       " ('hair', 0),\n",
       " ('.', 0),\n",
       " ('He', 0),\n",
       " ('is', 0),\n",
       " ('not', 0),\n",
       " ('worried', 0),\n",
       " ('about', 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "token_tuples[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52401a4-658a-4504-8c12-08646ba2a8fc",
   "metadata": {},
   "source": [
    "## Indexer Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48a3bf8-876b-48da-9a22-1e21a99c1059",
   "metadata": {},
   "source": [
    "Construct inverted index\n",
    "- the key is a unique token/term\n",
    "- the value is a list of `(docID, term_freq)` tuples for the token/term, here `term_freq` is the term frequency of the token/term in a document (i.e., the number of duplicated `(token, docID)` tuples)\n",
    "- An efficient implementation should scan each `(token, docID)` tuple in `sorted_token_tuples` only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be257825-29a5-4de1-94dc-ad005fac27d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct inverted index using the sorted list of (token, docID) tuples\n",
    "\n",
    "index = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7572ba4d-e80b-4491-b69f-9ba8f553918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_freq = dict() # how many documents contain the term\n",
    "for (token, docid) in sorted_token_tuples:\n",
    "    if token not in index:\n",
    "        index[token] = [(docid, 1)]\n",
    "        doc_freq[token] = 1\n",
    "    else:\n",
    "        docid_, tf = index[token][-1]\n",
    "        if docid_ == docid:\n",
    "            index[token][-1] = (docid, tf+1) # if same word appear in the same doc, frequency + 1\n",
    "        else:\n",
    "            index[token].append((docid, 1)) # if not same doc, meaning same word appear in another doc\n",
    "            doc_freq[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4e6220f-8649-4458-9a6a-0fd655ca8e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of indexed tokens/terms: 91\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of indexed tokens/terms: {len(index)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
